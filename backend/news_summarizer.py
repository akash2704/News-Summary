# news_summarizer.py
import logging
import requests
from newsapi import NewsApiClient
from bs4 import BeautifulSoup
import google.generativeai as genai
from gtts import gTTS
import os
import time
import random
import base64  # Add base64 for encoding audio

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configure Google Gemini API
API_KEY = os.getenv("NEWSAPI_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Validate API keys
if not API_KEY:
    logger.error("NEWSAPI_KEY not found in environment variables.")
    raise ValueError("NEWSAPI_KEY is required in the .env file.")
if not GEMINI_API_KEY:
    logger.error("GEMINI_API_KEY not found in environment variables.")
    raise ValueError("GEMINI_API_KEY is required in the .env file.")

# Configure Google Gemini API
genai.configure(api_key=GEMINI_API_KEY)

def fetch_news_articles(company_name, api_key, count=10):
    """Fetch news articles (title and URL) from NPR using NewsAPI."""
    try:
        newsapi = NewsApiClient(api_key=api_key)
        response = newsapi.get_everything(
            q=company_name,
            domains="npr.org",
            language="en",
            sort_by="publishedAt",
            page_size=count,
            page=1
        )
        if response["status"] != "ok":
            logger.error(f"NewsAPI error: {response.get('message', 'Unknown error')}")
            return []
        
        articles = [
            {
                "title": article["title"],
                "url": article["url"],
                "description": article["description"] or "No description available"
            }
            for article in response["articles"]
        ]
        logger.info(f"Fetched {len(articles)} articles from NewsAPI for {company_name}")
        return articles
    except Exception as e:
        logger.error(f"Error fetching news articles: {e}")
        return []

def extract_article_content(url):
    """Extract full article text from an NPR URL using BeautifulSoup."""
    headers = {
        "User-Agent": random.choice([
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36"
        ])
    }
    
    try:
        time.sleep(random.uniform(1, 3))
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, "html.parser")
        story_container = soup.find("div", id="storytext")
        if not story_container:
            logger.warning(f"No storytext container found for {url}, falling back to all <p> tags")
            paragraphs = soup.find_all("p")
        else:
            paragraphs = story_container.find_all("p")
        
        text = "\n".join(p.get_text().strip() for p in paragraphs if p.get_text().strip() and len(p.get_text().strip()) > 20)
        
        if not text:
            logger.warning(f"No substantial text found for {url}, using body text")
            body = soup.find("body")
            text = "\n".join(line.strip() for line in body.get_text().splitlines() if len(line.strip()) > 20) if body else ""
        
        if not text:
            logger.warning(f"No content extracted for {url}")
            return "No content extracted"
        
        logger.info(f"Successfully extracted text from {url}")
        return text
    except requests.exceptions.RequestException as e:
        logger.error(f"Request error for {url}: {e}")
        return "Error extracting content"
    except Exception as e:
        logger.error(f"Unexpected error for {url}: {e}")
        return "Error extracting content"

def generate_summary(text):
    """Generate a summary using Google Gemini."""
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")
        prompt = f"Summarize the following text in 2-3 sentences:\n\n{text}\n\nReturn only the summary."
        response = model.generate_content(prompt)
        summary = response.text.strip()
        if not summary:
            logger.warning("No summary generated by Gemini.")
            return "No summary available"
        return summary
    except Exception as e:
        logger.error(f"Error generating summary with Gemini: {e}")
        return "No summary available"

def translate_to_hindi(text):
    """Translate English text to Hindi using Google Gemini."""
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")
        prompt = f"Translate the following English text to Hindi:\n\n{text}\n\nReturn only the translated text."
        response = model.generate_content(prompt)
        translated_text = response.text.strip()
        if not translated_text:
            logger.warning("No translation generated by Gemini.")
            return text
        return translated_text
    except Exception as e:
        logger.error(f"Error translating to Hindi with Gemini: {e}")
        return text

def analyze_sentiment(text):
    """Perform sentiment analysis using Google Gemini."""
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")
        prompt = f"Analyze the sentiment of the following text and classify it as Positive, Negative, or Neutral:\n\n{text}\n\nReturn only the sentiment label (e.g., Positive, Negative, Neutral)."
        response = model.generate_content(prompt)
        sentiment = response.text.strip()
        if sentiment not in ["Positive", "Negative", "Neutral"]:
            logger.warning(f"Invalid sentiment label from Gemini: {sentiment}. Defaulting to Neutral.")
            return "Neutral"
        return sentiment
    except Exception as e:
        logger.error(f"Error analyzing sentiment with Gemini: {e}")
        return "Neutral"

def extract_topics(text):
    """Extract key topics using Google Gemini."""
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")
        prompt = f"Extract the top 5 key topics from the following text as a comma-separated list:\n\n{text}\n\nReturn only the topics (e.g., topic1, topic2, topic3, topic4, topic5)."
        response = model.generate_content(prompt)
        topics = [topic.strip() for topic in response.text.split(",")][:5]
        if not topics or topics == [""]:
            logger.warning("No topics extracted from Gemini. Defaulting to ['Unknown'].")
            return ["Unknown"]
        return topics
    except Exception as e:
        logger.error(f"Error extracting topics with Gemini: {e}")
        return ["Unknown"]

def comparative_analysis(articles):
    """Perform comparative sentiment and topic analysis."""
    sentiment_dist = {"Positive": 0, "Negative": 0, "Neutral": 0}
    for article in articles:
        sentiment_dist[article["sentiment"]] += 1

    coverage_diff = []
    topic_overlap = {"Common Topics": set(), "Unique Topics": {}}
    common_topics = set.intersection(*[set(a["topics"]) for a in articles]) if articles else set()
    topic_overlap["Common Topics"] = list(common_topics)

    for i, a1 in enumerate(articles):
        unique = set(a1["topics"]) - common_topics
        topic_overlap["Unique Topics"][f"Article {i+1}"] = list(unique)
        for j, a2 in enumerate(articles[i+1:], i+1):
            diff = f"Article {i+1} ({a1['sentiment']}) vs Article {j+1} ({a2['sentiment']})"
            impact = f"Focus: {', '.join(a1['topics'][:2])} vs {', '.join(a2['topics'][:2])}"
            coverage_diff.append({"Comparison": diff, "Impact": impact})

    return {
        "Sentiment Distribution": sentiment_dist,
        "Coverage Differences": coverage_diff,
        "Topic Overlap": topic_overlap
    }

def generate_hindi_tts(text, output_file="output.mp3"):
    """Generate Hindi TTS using gTTS and return base64-encoded audio."""
    try:
        tts = gTTS(text=text, lang="hi", slow=False)
        tts.save(output_file)
        # Read the file and encode it as base64
        with open(output_file, "rb") as audio_file:
            audio_data = audio_file.read()
            audio_base64 = base64.b64encode(audio_data).decode("utf-8")
        # Clean up the file to save space
        os.remove(output_file)
        return audio_base64
    except Exception as e:
        logger.error(f"Error generating TTS: {e}")
        return None

def process_articles(articles):
    """Process articles: extract content, summarize, analyze sentiment/topics, and generate Hindi TTS summaries."""
    processed_articles = []
    for i, article in enumerate(articles):
        # Extract full article text
        logger.info(f"Extracting content for article: {article['title']}")
        article["text"] = extract_article_content(article["url"])
        
        if article["text"] in ["No content extracted", "Error extracting content"]:
            logger.warning(f"Skipping article {article['title']} due to extraction failure")
            continue
        
        # Generate summary in English
        logger.info(f"Generating summary for article: {article['title']}")
        article["summary"] = generate_summary(article["text"])
        
        # Translate the summary to Hindi
        logger.info(f"Translating summary to Hindi for article: {article['title']}")
        article["hindi_summary"] = translate_to_hindi(article["summary"])
        
        # Analyze sentiment and extract topics
        logger.info(f"Analyzing sentiment and topics for article: {article['title']}")
        article["sentiment"] = analyze_sentiment(article["text"])
        article["topics"] = extract_topics(article["text"])
        
        # Generate Hindi TTS for the Hindi summary and encode as base64
        logger.info(f"Generating Hindi TTS for summary of article: {article['title']}")
        output_file = f"summary_{i+1}.mp3"
        audio_base64 = generate_hindi_tts(article["hindi_summary"], output_file=output_file)
        article["hindi_tts_base64"] = audio_base64 if audio_base64 else "TTS generation failed"
        
        processed_articles.append(article)
    
    return processed_articles

def fetch_and_process_articles(company_name):
    """Fetch articles from NewsAPI, process them, and perform comparative analysis."""
    articles = fetch_news_articles(company_name, API_KEY)
    if not articles:
        return [], {}

    # Process articles
    processed_articles = process_articles(articles)
    if not processed_articles:
        logger.error("No articles processed successfully.")
        return [], {}

    # Perform comparative analysis
    analysis_results = comparative_analysis(processed_articles)
    return processed_articles, analysis_results